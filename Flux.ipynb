{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpowadzenie do deep learning w bibliotece Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Flux](http://fluxml.ai/) jest biblioteką Julii przeznaczoną do tworzenia modeli uczenia maszynowego.\n",
    "- Jest w całości oparta na Julii, przez co trywialne jest jej modyfikowanie i dostosowywanie do swoich potrzeb. \n",
    "- Możliwe jest przy tym wykorzystanie wewnątrz modeli składni, funkcji i makr Julii.\n",
    "- Przy czym tworzenie całkiem złożonych standardowych modeli jest intuicyjne i szybkie, zazwyczaj zajmują one jedynie kilka linijek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby w  zrozumieć sposób pracy z Fluxem warto rozpatrzeć prosty przykład. Zajmiemy się przetwarzaniem języka naturalnego - zbudujemy model zdolny do generowania składnej wypowiedzi w języku polskim.\n",
    "\n",
    "Wyjściowe założenie jest takie, że wytrenujemy sieć neuronową, która będzie estymowała prawdopodobieństwo wystąpienia danego znaku w ciągu na podstawie poprzedzających go znaków w sekwencji ([<b>Character-Level Language Model</b>](http://karpathy.github.io/2015/05/21/rnn-effectiveness/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiórem na którym będziemy pracowali jest <i>W poszukiwaniu straconego czasu</i> Marcela Prousta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://upload.wikimedia.org/wikipedia/commons/b/b8/Marcel_Proust_1895.jpg)](https://pl.wikipedia.org/wiki/Marcel_Proust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(...) matka widząc, że mi jest zimno, namówiła mnie, abym się napił wbrew zwyczajowi trochę herbaty. Odmówiłem zrazu; potem, nie wiem czemu, namyśliłem się. Posłała po owe krótkie i pulchne ciasteczka zwane magdalenkami, które wyglądają jak odlane w prążkowanej skorupie muszli. I niebawem (...) machinalnie podniosłem do ust łyżeczkę herbaty, w której rozmoczyłem kawałek magdalenki. Ale w tej samej chwili, kiedy łyk pomieszany z okruchami ciasta dotknął mego podniebienia, zadrżałem, czując, że się we mnie dzieje coś niezwykłego. Owładnęła mną rozkoszna słodycz (...). Sprawiła, że w jednej chwili koleje życia stały mi się obojętne, klęski jako błahe, krótkość złudna (...). Cofam się myślą do chwili, w której wypiłem pierwszą łyżeczkę herbaty (...). I nagle wspomnienie zjawiło mi się. Ten smak to była magdalenka cioci Leonii.(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim jednak zaczniemy wprowadźmy odrobinę teorii stojącej za tym zagadnieniem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rekurencyjne sieci neuronowe (Recurrent neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Charakterystyczną cechą tego typu sieci jest to, że pozwalają one na istnienie wewnątrz grafu cykli skierowanych.\n",
    "- Oznacza to, że informacja wewnątrz takiej sieci nie musi płynąć tylko w jednym kierunku - neurony leżące na tej samej warstwie także mogą przesyłać sobie wzajemnie dane:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/diags.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzięki tej właściwości RNN doskonale nadają się do budowy interesującego nas modelu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://karpathy.github.io/assets/rnn/charseq.jpeg)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Long short-term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problemem na który można natrafić w przypadku korzystania z RNN jest pamięć takiej sieci. Gdy odległość pomiędzy aktualnym a poprzedzającymi go węzłami, które niosą za sobą kluczową informację jest niewielka, sieć jest w stanie efektywnie je wykorzystać:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Problem się pojawia gdy ta odległość jest duża - wtedy kluczowe informacje po prostu znikają w szumie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtedy też, warto zastosować sieć LSTM, która ze względu na swoją architekturę jest w stanie odpowiednio filtrować informację i wykorzystawać je nawet wtedy, gdy ich źródło jest znacznie oddalone od aktualnego neuronu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Przejdźmy teraz do implementowania modelu za pomocą Fluxa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehot, argmax, chunk, batchseq, throttle, crossentropy\n",
    "using StatsBase: wsample\n",
    "using Base.Iterators: partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem jest oczywiście odpowiednie przygotowanie danych na których będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = collect(readstring(\"w_poszukiwaniu.txt\"));\n",
    "alphabet = [unique(text)..., '_'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie kodujemy zmienne jakościowe - wykorzystać do tego możemy funkcję [<tt>onehot</tt>](http://fluxml.ai/Flux.jl/stable/data/onehot.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = map(ch -> onehot(ch, alphabet), text);\n",
    "stop = onehot('_', alphabet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = length(alphabet);\n",
    "seqlen = 50;\n",
    "nbatch = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs = collect(partition(batchseq(chunk(text, nbatch), stop), seqlen));\n",
    "Ys = collect(partition(batchseq(chunk(text[2:end], nbatch), stop), seqlen));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Char,1},1}:\n",
       " ['a', 'l', 'a', ' ']\n",
       " ['m', 'a', ' ', 'k']\n",
       " ['o', 't', 'a']     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = chunk(\"ala ma kota\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Array{Char,1},1}:\n",
       " ['a', 'm', 'o']\n",
       " ['l', 'a', 't']\n",
       " ['a', ' ', 'a']\n",
       " [' ', 'k', '_']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = batchseq(q, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array{Char,1}[['a', 'm', 'o'], ['l', 'a', 't']]\n",
      "Array{Char,1}[['a', ' ', 'a'], [' ', 'k', '_']]\n"
     ]
    }
   ],
   "source": [
    "for i in partition(w, 2)\n",
    "   println(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{Array{Char,1},1},1}:\n",
       " Array{Char,1}[['a', 'm', 'o'], ['l', 'a', 't']]\n",
       " Array{Char,1}[['a', ' ', 'a'], [' ', 'k', '_']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(partition(w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{Array{Char,1},1},1}:\n",
       " Array{Char,1}[['l', 'a', 't'], ['a', ' ', 'a']]\n",
       " Array{Char,1}[[' ', 'k', '_'], ['m', 'o', '_']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect(partition(batchseq(chunk(\"ala ma kota\"[2:end], 3), '_'),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Definiowanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy dane są już gotowe kolejnym krokiem jest odpowiednie zdefiniowanie modelu na którym będziemy pracować. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od ręcznego zdefiniowania prostej regresji logistycznej (na początek załóżmy, że wagi są już zoptymalizowane):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.575108\n",
       " 0.910523\n",
       " 0.464536\n",
       " 0.920674"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(4, 8)\n",
    "b = rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit(x) = 1.0 ./ (1.0+exp.(-W*x .- b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.982528\n",
       " 0.970391\n",
       " 0.957775\n",
       " 0.975082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rand(8)\n",
    "logit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdybyśmy chcieli wyuczyć ten model we Fluxie to powyższa definicja regresji logistycznej nam wystarczy - musimy jedynie zadeklerować <tt>W</tt> i <tt>b</tt> jako trenowalne parametry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 4-element Array{Float64,1}:\n",
       " 0.575108\n",
       " 0.910523\n",
       " 0.464536\n",
       " 0.920674"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux.Tracker\n",
    "\n",
    "W = param(W)\n",
    "b = param(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście pracując na Fluxie nie musimy deklarować wszystkiego ręcznie, dostarcza on najpopularniejsze [funkcje aktywacji](http://fluxml.ai/Flux.jl/stable/models/layers.html#Activation-Functions-1), które możemy wykorzystać w naszym modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit2 (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2(x) = σ.(W * x .+ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 4-element Array{Float64,1}:\n",
       " 0.982528\n",
       " 0.970391\n",
       " 0.957775\n",
       " 0.975082"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogicznie nie ma konieczności definiowania [warstw modelu](http://fluxml.ai/Flux.jl/stable/models/layers.html#Basic-Layers-1) ręcznie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(8, 4, NNlib.σ)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3 = Dense(8,4,σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 4-element Array{Float64,1}:\n",
       " 0.466505\n",
       " 0.364813\n",
       " 0.566985\n",
       " 0.21928 "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy czym gdy żadna z dostarczonych razem z Fluxem definicji warstwy nam nie odpowiada możemy w banalny sposób zadeklarować własną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 5-element Array{Float64,1}:\n",
       " -0.745883\n",
       " -0.205312\n",
       " -1.01167 \n",
       "  2.52542 \n",
       "  2.44472 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Affine\n",
    "  W\n",
    "  b\n",
    "end\n",
    "\n",
    "Affine(in::Integer, out::Integer) =\n",
    "  Affine(param(randn(out, in)), param(randn(out)))\n",
    "\n",
    "# Overload call, so the object can be used as a function\n",
    "(m::Affine)(x) = m.W * x.^2 .+ m.b\n",
    "\n",
    "a = Affine(10, 5)\n",
    "\n",
    "a(rand(10)) # => 5-element vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy chcemy móc w pełni wykorzystać wszystkie przydatne funkcje Fluxa musimy jeszcze skorzystać z funkcji <tt>treelike</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Flux.treelike(Affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wróćmy do generatora tekstu nad którym pracujemy. Zdefiniujemy go następująco:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Recur(LSTMCell(124, 512)), Recur(LSTMCell(512, 512)), Dense(512, 124), NNlib.softmax)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "  LSTM(N, 512),\n",
    "  LSTM(512, 512),\n",
    "  Dense(512, N),\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo też:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = LSTM(N, 512);\n",
    "layer2 = LSTM(512, 512);\n",
    "layer3 = Dense(512, N);\n",
    "layer4 = softmax;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m1 (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1(x) = layer4(layer3(layer2(layer1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m2 (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2(x) = layer1(x) |> layer2 |> layer3 |> layer4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "czy też jako złożenie funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#55) (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = layer1 ∘ layer2 ∘ layer3 ∘ layer4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając już gotową definicję modelu możemy przejść do kolejnego punktu - wyboru funkcji celu i regularyzacji modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja straty, regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak poprzednio funkcję straty możemy zdefiniować samodzielnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Dense(5,2)\n",
    "\n",
    "x, y = rand(5), rand(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(ŷ, y) = sum((ŷ.- y).^2)/ length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6380764053807677 (tracked)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model(x), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystać [jedną z zaimplementowanych we Fluxie:](https://github.com/FluxML/Flux.jl/blob/8f73dc6e148eedd11463571a0a8215fd87e7e05b/src/layers/stateless.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6380764053807677 (tracked)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.mse(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albo wziąć ją z innej biblioteki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DomainError:",
     "output_type": "error",
     "traceback": [
      "DomainError:",
      "",
      "Stacktrace:",
      " [1] \u001b[1mtrack\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Flux\\src\\tracker\\Tracker.jl:41\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1mtrack\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Flux\\src\\tracker\\Tracker.jl:42\u001b[22m\u001b[22m [inlined]",
      " [3] \u001b[1msqrt\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Flux\\src\\tracker\\scalar.jl:44\u001b[22m\u001b[22m [inlined]",
      " [4] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Distances\\src\\bhattacharyya.jl:26\u001b[22m\u001b[22m [inlined]",
      " [5] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\simdloop.jl:73\u001b[22m\u001b[22m [inlined]",
      " [6] \u001b[1mbhattacharyya_coeff\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TrackedArray{…,Array{Float64,1}}, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Distances\\src\\bhattacharyya.jl:23\u001b[22m\u001b[22m",
      " [7] \u001b[1mevaluate\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Distances.HellingerDist, ::TrackedArray{…,Array{Float64,1}}, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Distances\\src\\bhattacharyya.jl:46\u001b[22m\u001b[22m",
      " [8] \u001b[1mhellinger\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TrackedArray{…,Array{Float64,1}}, ::Array{Float64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\p\\.julia\\v0.6\\Distances\\src\\bhattacharyya.jl:47\u001b[22m\u001b[22m",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "using Distances\n",
    "hellinger(model(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie [regularyzacja](http://fluxml.ai/Flux.jl/stable/models/regularisation.html) jest dość [intuicyjna](http://fluxml.ai/Flux.jl/stable/models/layers.html#Normalisation-and-Regularisation-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty() = vecnorm(model.W) + vecnorm(model.b)\n",
    "loss(ŷ,y) = Flux.mse(ŷ,y) + penalty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.063592957484005 (tracked)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W budowanym modelu funkcja straty wyglądać będzie następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(xs, ys)\n",
    "  l = sum(Flux.crossentropy.(m.(xs), ys))\n",
    "  Flux.truncate!(m)\n",
    "  return l\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zdefiniowaniu modelu i funkcji celu możemy przystąpić do trenowania sieci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście podstawą, której potrzebujemy jest odpowiedni algorytm optymalizacyjny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function update!(ps, η = .0001)\n",
    "  for w in ps\n",
    "    w.data .-= w.grad .* η\n",
    "    w.grad .= 0\n",
    "  end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while true\n",
    "  back!(loss(model(x),y))\n",
    "  max(maximum(abs.(W.grad)), abs(b.grad[1])) > 0.001 || break\n",
    "  update!((W, b))\n",
    "  i += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albo też wykorzystać [gotowy algorytm](http://fluxml.ai/Flux.jl/stable/training/optimisers.html) zaimplementowany we Fluxie: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(params(m), 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux jest zdolny do kontrolowania całej procedury uczenia, służy do tego funkcja <tt>train!</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(objective, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozwala ona też na definiowanie wywołań, które pozwolą nam kontrolować przebieg uczenia.\n",
    "\n",
    "Po omówieniu wszystkich elementów składowych biblioteki możemy złożyć naszą sieć w całość:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "  LSTM(N, 512),\n",
    "  LSTM(512, 512),\n",
    "  Dense(512, N),\n",
    "  softmax)\n",
    "\n",
    "function loss(xs, ys)\n",
    "  l = sum(crossentropy.(m.(xs), ys))\n",
    "  Flux.truncate!(m)\n",
    "  return l\n",
    "end\n",
    "\n",
    "opt = ADAM(params(m), 0.001)\n",
    "\n",
    "#evalcb = () -> @show loss(Xs[5], Ys[5])\n",
    "\n",
    "function sample(m, alphabet, len; temp = 1)\n",
    "  Flux.reset!(m)\n",
    "  buf = IOBuffer()\n",
    "  c = rand(alphabet)\n",
    "  for i = 1:len\n",
    "    write(buf, c)\n",
    "    c = wsample(alphabet, m(onehot(c, alphabet)).data)\n",
    "  end\n",
    "  return String(take!(buf))\n",
    "end\n",
    "\n",
    "evalcb = function ()\n",
    "    @show loss(Xs[5], Ys[5])\n",
    "    println(sample(deepcopy(m), alphabet, 100))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time Flux.train!(loss, zip(Xs, Ys), opt,\n",
    "cb = throttle(evalcb, 240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście taka sieć może liczyć się strasznie długo. Ten proces można przyśpieszyć za pomocą wbudowanym w Julię wsparciu [obliczeń na GPU](http://fluxml.ai/Flux.jl/stable/gpu.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatywy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux nie jest jedyną biblioteką, która umożliwia budowanie modeli uczenia maszynowego w Julii. Poniżej wymienionych jest kilka alternatywnych możliwości:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Knet.jl](https://github.com/denizyuret/Knet.jl)\n",
    "- [MXnet.jl](https://github.com/dmlc/MXNet.jl)\n",
    "- [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
